## 📚 01. 카프카 시작하기

### 핵심 요약

모든 기업은 데이터로 움직이다. 데이터를 이동시키는 작업에 더 적은 노력을 들일수록 핵심 비즈니스에 더욱 집중할 수 있다.
-> 데이터를 어떻게 이동시키냐의 문제는 데이터 그 자체만큼이나 중요한 것이다.

#### 발행/구독 메시지 전달

- 발행/구독 메시지 전달 패턴의 특징은 전송자가 데이터를 보낼 때 직접 수신자로 보내지 않는다는 것이다.
- 전송자는 어떤 형태로든 메시지를 분류해서 보내고, 수신자는 이렇게 분류된 메시지를 구독한다.
- 발행 구독 시스템에는 대게 발행된 메시지를 전달받고 중계해주는 중간 지점 역할을 하는 브로커가 있다.

##### 초기의 발행/구독 시스템

- 간단한 메시지 큐나 프로세스간 통신 채널을 놓는 것.
- 프론트엔드 서버 > 지표서버 < 프론트엔드 서버 <br>
  ![kafka](https://github.com/user-attachments/assets/6d84f46d-5d32-46db-b9b0-47b1d64a04d0)

- 지표를 받아서 저장하고 분석하는 서비스, 지표를 생성하는 서비스,.. 등등이 추가되면 서로 연결고리가 더욱 많아짐
  -> 모든 애플리케이션으로부터 지표를 받는 하나의 앱을 만들고 이 지푯값들을 필요로 하는 어느 시스템이든 지표를 질의할 수 있도록 해주는 서버를 제공하자. <br>
  ![kafka2](https://github.com/user-attachments/assets/5db06acd-602d-40e0-8219-96197bc54ae0)

##### 개별 매시지 큐 시스템

- 지표를 다루는 것과 동시에 로그 메시지에 대해서도 비슷한 작업을 해줘야 한다.
- 이러한 경우에도 비슷한 시스템을 구성함으로써 정보의 발행자와 구독자를 분리할 수 있다.
  ![1-4](https://github.com/user-attachments/assets/bb29052a-abae-4322-a2fc-68cb021c92d6)

- 그러나 여기에는 중복이 많다. 버드고 한계도 제각각인 다수의 데이터 큐 시스템을 유지 관리해야 한다.
- 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요하다.

#### 카프카 입문

카프카는 위에서 설명한 것과 같은 문제를 해결하기 위해 고안된 메시지 발행/구독 시스템이다.
**분산 커밋 로그** 혹은 **분산 스트리밍 플랫폼** 이라고 불리기도 한다.
카프카에 저장된 데이터는 순서를 유지한 채로 지속성 있게 보관되며 결정적으로 읽을 수 있다.
확장시 성능을 향상 시키고 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 분산시켜 저장할 수 있다.

##### 메시지와 배치

- 데이터의 기본 단위는 **메시지**다. 카프카의 입장에서 메시지는 단순 바이트의 배열로 여기에 포함된 데이터에는 형식이나 의미가 없다.
- 메시지는 **키**라 불리는 메타데이터를 포함할 수 있다. 키 역시 의미없는 바이트 배열이다. 키는 메시지를 저장할 파티션을 결정하기 위해 사용된다.
- 카프카는 효율성을 위해 메시지를 **배치** 단위로 저장한다. 배시지는 같은 토픽의 파티션에 쓰여지는 메시지의 집합이다.

##### 스키마

- 카프카 입장에서 메시지는 단순한 바이트 배열이지만, 일정한 구조를 부여하는 것이 권장된다.
- JSON, XML: 가장 간단하고 쓰기 쉽다. 하지만 타입 처리 기능이나 스키마 버전 간의 호환성 유지 기능이 떨어진다.

카프카에서는 일관적인 데이터 형식이 중요함. 메시지 쓰기와 읽기 작ㅇ버을 분리할 수 있도록 해주기 때문이다.
이 작업들이 결합되어 있다면 메시지를 구독하는 애플리케이션들 먼저 구버전과 신버전 형식을 동시에 함께 지원할 수 있도록 업데이트 되어야 한다.
그 다음에야 메시지를 발행하는 애플리케이션이 신버전 형식을 사용하도록 업데이트 될 수 ㅣㅆ을 것이다

=> 잘 정의된 스키마를 공유 저장소에 저장함으로써 카프카는 두 버전 형식을 도잇에 지원하도록 하는 작업 없이도 메시지를 처리할 수 있다.

### 느낀점/적용
